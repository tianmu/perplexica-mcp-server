# Perplexica MCP服务器配置示例
# 本地测试才需要，复制此文件为 .env 并根据需要修改配置

# Perplexica服务器地址
PERPLEXICA_BASE_URL=http://localhost:3000

# 请求超时时间（秒）
PERPLEXICA_TIMEOUT=30

# 默认优化模式 (balanced, speed, quality)
PERPLEXICA_OPTIMIZATION_MODE=balanced

# 默认输出格式 (json, formatted)
PERPLEXICA_DEFAULT_OUTPUT_FORMAT=json

# 默认聊天模型配置
PERPLEXICA_DEFAULT_CHAT_PROVIDER=openai
PERPLEXICA_DEFAULT_CHAT_MODEL=gpt-4.1

# 默认嵌入模型配置（推荐配置：transformers）
PERPLEXICA_DEFAULT_EMBEDDING_PROVIDER=transformers
PERPLEXICA_DEFAULT_EMBEDDING_MODEL=xenova-bge-small-en-v1.5

# Custom OpenAI配置（当使用custom_openai provider时）
PERPLEXICA_CUSTOM_OPENAI_BASE_URL=
PERPLEXICA_CUSTOM_OPENAI_KEY=

# 日志级别 (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# ===============================================
# 其他可选配置示例（取消注释使用）
# ===============================================

# 标准OpenAI配置
# PERPLEXICA_DEFAULT_CHAT_PROVIDER=openai
# PERPLEXICA_DEFAULT_CHAT_MODEL=gpt-4o-mini
# PERPLEXICA_DEFAULT_EMBEDDING_PROVIDER=openai
# PERPLEXICA_DEFAULT_EMBEDDING_MODEL=text-embedding-3-large

# Anthropic配置
# PERPLEXICA_DEFAULT_CHAT_PROVIDER=anthropic
# PERPLEXICA_DEFAULT_CHAT_MODEL=claude-3-sonnet-20240229

# 本地模型配置（Ollama）
# PERPLEXICA_DEFAULT_CHAT_PROVIDER=ollama
# PERPLEXICA_DEFAULT_CHAT_MODEL=llama2